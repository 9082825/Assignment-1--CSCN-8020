{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1f7c9b2",
   "metadata": {},
   "source": [
    "# CSCN8020 - Assignment 1:\n",
    "\n",
    "\n",
    "# Problem 1\n",
    "## Pick-and-Place Robot MDP Design\n",
    "\n",
    "### Problem Statement\n",
    "Design a reinforcement learning problem as an MDP for controlling a robot arm in a repetitive pick-and-place task. The goal is to learn movements that are fast and smooth through direct motor control.\n",
    "\n",
    "---\n",
    "\n",
    "### MDP Components\n",
    "\n",
    "#### States (S)\n",
    "The state space captures all information necessary for effective control decisions:\n",
    "\n",
    "- **Joint angles**: θ = (θ₁, θ₂, ..., θₙ) for each joint in the arm\n",
    "- **Joint angular velocities**: θ̇ = (θ̇₁, θ̇₂, ..., θ̇ₙ) for each joint\n",
    "- **End-effector position**: (x, y, z) in 3D space\n",
    "- **Gripper state**: (open/closed)\n",
    "- **Object status**: (held/not held)\n",
    "- **Target position**: Current pick or place location\n",
    "\n",
    "**Reasoning**: Positions tell us where the arm is located, while velocities are essential for achieving smooth motion and avoiding jerky movements. Task status information (gripper and object states) helps the agent know whether to pick or place. Since the objective emphasizes smooth movements, velocity information is crucial for the learning process.\n",
    "\n",
    "---\n",
    "\n",
    "#### Actions (A)\n",
    "The action space consists of continuous motor commands:\n",
    "\n",
    "- **Motor torques**: τ = (τ₁, τ₂, ..., τₙ) applied to each joint\n",
    "- **Gripper command**: (open/close/hold)\n",
    "\n",
    "**Reasoning**: Since we're controlling motors directly, actions should be torque commands or voltage signals to each motor. Continuous actions allow for smooth, precise control, which directly aligns with the smoothness objective. This low-level control gives the agent the flexibility to learn optimal trajectories.\n",
    "\n",
    "---\n",
    "\n",
    "#### Rewards (R)\n",
    "A composite reward function that balances speed, smoothness, and task completion:\n",
    "\n",
    "**R(s, a, s') = R_task + R_speed + R_smoothness + R_energy**\n",
    "\n",
    "**Components:**\n",
    "\n",
    "1. **Task Rewards (R_task)**:\n",
    "   - +100 for successful object pick\n",
    "   - +100 for successful object placement\n",
    "   - -1 per timestep (encourages faster task completion)\n",
    "\n",
    "2. **Speed Rewards (R_speed)**:\n",
    "   - -0.1 × time_elapsed (encourages faster movements)\n",
    "\n",
    "3. **Smoothness Rewards (R_smoothness)**:\n",
    "   - -α × ||a - a_prev||² (penalizes sudden changes in motor commands)\n",
    "\n",
    "4. **Energy Rewards (R_energy)**:\n",
    "   - -β × ||a||² (penalizes excessive motor torque, encourages efficiency)\n",
    "\n",
    "**Additional Penalties:**\n",
    "- -50 for dropping the object\n",
    "- -10 for collisions with workspace boundaries\n",
    "- -5 for excessive joint velocities\n",
    "\n",
    "**Reasoning**: The reward structure directly addresses the learning objectives. Task completion rewards ensure the robot fulfills its function. Time penalties encourage speed. Smoothness penalties (penalizing large changes between consecutive actions) promote smooth trajectories by discouraging abrupt motor command changes. Energy penalties prevent wasteful movements and protect the hardware. This multi-objective reward naturally guides the agent toward desired behaviors.\n",
    "\n",
    "---\n",
    "\n",
    "#### Transition Dynamics (P)\n",
    "The transition function P(s'|s, a) is determined by the physics of the robot arm:\n",
    "\n",
    "- **Forward dynamics equations**: How applied torques affect joint accelerations\n",
    "- **Kinematic constraints**: Joint limits and workspace boundaries\n",
    "- **Contact dynamics**: Gripper-object interaction physics\n",
    "- **Environmental factors**: Gravity, friction, and inertia\n",
    "\n",
    "**Reasoning**: In model-free RL, we may not explicitly model these dynamics, but the environment simulator must encode the physical laws governing robot motion. The deterministic or stochastic nature depends on factors like sensor noise and environmental uncertainty.\n",
    "\n",
    "---\n",
    "\n",
    "### Additional Design Considerations\n",
    "\n",
    "1. **Discount Factor (γ)**: Use γ ≈ 0.95-0.99 to balance immediate rewards (speed) with long-term trajectory smoothness\n",
    "\n",
    "2. **Episode Structure**: Each episode starts with the object at the pick location and ends when successfully placed at the target or after a maximum timeout\n",
    "\n",
    "3. **State Representation**: For real implementation, continuous states would likely use function approximation (neural networks) rather than discretization\n",
    "\n",
    "4. **Action Space**: Continuous control is preferred, potentially using algorithms like DDPG, TD3, or SAC\n",
    "\n",
    "---\n",
    "\n",
    "### Talking Points:\n",
    "\n",
    "For this pick-and-place robot task, I've designed an MDP that enables learning of fast and smooth movements through direct motor control.\n",
    "\n",
    "The **state space** includes joint angles, joint velocities, end-effector position, gripper state, and object status. Including velocities is critical because smooth motion depends on understanding movement dynamics, not just positions.\n",
    "\n",
    "**Actions** are continuous motor torques applied to each joint, plus gripper commands. This low-level control allows the agent to learn precise, smooth trajectories.\n",
    "\n",
    "The **reward function** balances multiple objectives: task completion bonuses (+100 for successful pick/place), time penalties to encourage speed (-1 per timestep), smoothness penalties that discourage abrupt motor command changes (-α × ||a - a_prev||²), and energy penalties to prevent excessive torques. This structure directly incentivizes the desired behavior.\n",
    "\n",
    "**Transition dynamics** follow the physical laws governing the robot arm—how torques affect joint motion and object interactions.\n",
    "\n",
    "This formulation provides sufficient information for learning while the reward design naturally guides the agent toward efficient, smooth pick-and-place behaviors.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf737b02",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "## Value Iteration on 2×2 Gridworld (Manual Calculation)\n",
    "\n",
    "### Problem Statement\n",
    "Perform two iterations of Value Iteration for a 2×2 gridworld environment. Show the step-by-step process (without code) including policy evaluation and policy improvement.\n",
    "\n",
    "---\n",
    "\n",
    "### Environment Setup\n",
    "\n",
    "#### Grid Layout\n",
    "```\n",
    "[s1: R=5]   [s2: R=10]\n",
    "[s3: R=1]   [s4: R=2]\n",
    "```\n",
    "\n",
    "#### Environment Characteristics\n",
    "\n",
    "**State Space (S)**: {s1, s2, s3, s4}\n",
    "\n",
    "**Action Space (A)**: {up, down, left, right}\n",
    "\n",
    "**Initial Policy (π)**: For all states, π(up|s) = 1\n",
    "\n",
    "**Transition Probabilities P(s'|s, a)**:\n",
    "- If the action is valid (does not run into a wall), the transition is deterministic\n",
    "- Otherwise, s' = s (agent stays in current state)\n",
    "\n",
    "**Rewards R(s)**:\n",
    "- R(s1) = 5 for all actions a\n",
    "- R(s2) = 10 for all actions a\n",
    "- R(s3) = 1 for all actions a\n",
    "- R(s4) = 2 for all actions a\n",
    "\n",
    "**Discount Factor**: γ = 0.9 (assumed)\n",
    "\n",
    "---\n",
    "\n",
    "### Value Iteration Algorithm\n",
    "\n",
    "The Bellman optimality equation used for value iteration:\n",
    "\n",
    "\\[ V(s) = \\max_a \\sum_{s'} P(s'|s,a) [R(s) + \\gamma V(s')] \\]\n",
    "\n",
    "For deterministic transitions, this simplifies to:\n",
    "\n",
    "\\[ V(s) = \\max_a [R(s) + \\gamma V(s')] \\]\n",
    "\n",
    "---\n",
    "\n",
    "## Iteration 0: Initial Value Function\n",
    "\n",
    "All states start with zero value:\n",
    "\n",
    "| State | V₀(s) |\n",
    "|-------|-------|\n",
    "| s1    | 0.0   |\n",
    "| s2    | 0.0   |\n",
    "| s3    | 0.0   |\n",
    "| s4    | 0.0   |\n",
    "\n",
    "**Grid Visualization:**\n",
    "```\n",
    "[0.0]  [0.0]\n",
    "[0.0]  [0.0]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Iteration 1: First Value Update\n",
    "\n",
    "### State s1 (Top-Left, R=5)\n",
    "\n",
    "Calculate value for each action:\n",
    "\n",
    "- **up**: Hits wall → stays at s1\n",
    "  - V = R(s1) + γ × V₀(s1) = 5 + 0.9(0) = **5.0**\n",
    "\n",
    "- **down**: Moves to s3\n",
    "  - V = R(s1) + γ × V₀(s3) = 5 + 0.9(0) = **5.0**\n",
    "\n",
    "- **left**: Hits wall → stays at s1\n",
    "  - V = R(s1) + γ × V₀(s1) = 5 + 0.9(0) = **5.0**\n",
    "\n",
    "- **right**: Moves to s2\n",
    "  - V = R(s1) + γ × V₀(s2) = 5 + 0.9(0) = **5.0**\n",
    "\n",
    "**V₁(s1) = max(5.0, 5.0, 5.0, 5.0) = 5.0**\n",
    "\n",
    "---\n",
    "\n",
    "### State s2 (Top-Right, R=10)\n",
    "\n",
    "Calculate value for each action:\n",
    "\n",
    "- **up**: Hits wall → stays at s2\n",
    "  - V = R(s2) + γ × V₀(s2) = 10 + 0.9(0) = **10.0**\n",
    "\n",
    "- **down**: Moves to s4\n",
    "  - V = R(s2) + γ × V₀(s4) = 10 + 0.9(0) = **10.0**\n",
    "\n",
    "- **left**: Moves to s1\n",
    "  - V = R(s2) + γ × V₀(s1) = 10 + 0.9(0) = **10.0**\n",
    "\n",
    "- **right**: Hits wall → stays at s2\n",
    "  - V = R(s2) + γ × V₀(s2) = 10 + 0.9(0) = **10.0**\n",
    "\n",
    "**V₁(s2) = max(10.0, 10.0, 10.0, 10.0) = 10.0**\n",
    "\n",
    "---\n",
    "\n",
    "### State s3 (Bottom-Left, R=1)\n",
    "\n",
    "Calculate value for each action:\n",
    "\n",
    "- **up**: Moves to s1\n",
    "  - V = R(s3) + γ × V₀(s1) = 1 + 0.9(0) = **1.0**\n",
    "\n",
    "- **down**: Hits wall → stays at s3\n",
    "  - V = R(s3) + γ × V₀(s3) = 1 + 0.9(0) = **1.0**\n",
    "\n",
    "- **left**: Hits wall → stays at s3\n",
    "  - V = R(s3) + γ × V₀(s3) = 1 + 0.9(0) = **1.0**\n",
    "\n",
    "- **right**: Moves to s4\n",
    "  - V = R(s3) + γ × V₀(s4) = 1 + 0.9(0) = **1.0**\n",
    "\n",
    "**V₁(s3) = max(1.0, 1.0, 1.0, 1.0) = 1.0**\n",
    "\n",
    "---\n",
    "\n",
    "### State s4 (Bottom-Right, R=2)\n",
    "\n",
    "Calculate value for each action:\n",
    "\n",
    "- **up**: Moves to s2\n",
    "  - V = R(s4) + γ × V₀(s2) = 2 + 0.9(0) = **2.0**\n",
    "\n",
    "- **down**: Hits wall → stays at s4\n",
    "  - V = R(s4) + γ × V₀(s4) = 2 + 0.9(0) = **2.0**\n",
    "\n",
    "- **left**: Moves to s3\n",
    "  - V = R(s4) + γ × V₀(s3) = 2 + 0.9(0) = **2.0**\n",
    "\n",
    "- **right**: Hits wall → stays at s4\n",
    "  - V = R(s4) + γ × V₀(s4) = 2 + 0.9(0) = **2.0**\n",
    "\n",
    "**V₁(s4) = max(2.0, 2.0, 2.0, 2.0) = 2.0**\n",
    "\n",
    "---\n",
    "\n",
    "### Updated Value Function After Iteration 1\n",
    "\n",
    "| State | V₁(s) |\n",
    "|-------|-------|\n",
    "| s1    | 5.0   |\n",
    "| s2    | 10.0  |\n",
    "| s3    | 1.0   |\n",
    "| s4    | 2.0   |\n",
    "\n",
    "**Grid Visualization:**\n",
    "```\n",
    "[5.0]   [10.0]\n",
    "[1.0]   [2.0]\n",
    "```\n",
    "\n",
    "**Observation**: After the first iteration, the values equal the immediate rewards since all successor state values were zero.\n",
    "\n",
    "---\n",
    "\n",
    "## Iteration 2: Second Value Update\n",
    "\n",
    "Now we use V₁ values from Iteration 1 to update each state.\n",
    "\n",
    "### State s1 (Top-Left, R=5)\n",
    "\n",
    "Calculate value for each action:\n",
    "\n",
    "- **up**: Hits wall → stays at s1\n",
    "  - V = R(s1) + γ × V₁(s1) = 5 + 0.9(5.0) = 5 + 4.5 = **9.5**\n",
    "\n",
    "- **down**: Moves to s3\n",
    "  - V = R(s1) + γ × V₁(s3) = 5 + 0.9(1.0) = 5 + 0.9 = **5.9**\n",
    "\n",
    "- **left**: Hits wall → stays at s1\n",
    "  - V = R(s1) + γ × V₁(s1) = 5 + 0.9(5.0) = 5 + 4.5 = **9.5**\n",
    "\n",
    "- **right**: Moves to s2\n",
    "  - V = R(s1) + γ × V₁(s2) = 5 + 0.9(10.0) = 5 + 9.0 = **14.0** ✓\n",
    "\n",
    "**V₂(s1) = max(9.5, 5.9, 9.5, 14.0) = 14.0**\n",
    "\n",
    "**Best Action**: right (move to s2)\n",
    "\n",
    "---\n",
    "\n",
    "### State s2 (Top-Right, R=10)\n",
    "\n",
    "Calculate value for each action:\n",
    "\n",
    "- **up**: Hits wall → stays at s2\n",
    "  - V = R(s2) + γ × V₁(s2) = 10 + 0.9(10.0) = 10 + 9.0 = **19.0** ✓\n",
    "\n",
    "- **down**: Moves to s4\n",
    "  - V = R(s2) + γ × V₁(s4) = 10 + 0.9(2.0) = 10 + 1.8 = **11.8**\n",
    "\n",
    "- **left**: Moves to s1\n",
    "  - V = R(s2) + γ × V₁(s1) = 10 + 0.9(5.0) = 10 + 4.5 = **14.5**\n",
    "\n",
    "- **right**: Hits wall → stays at s2\n",
    "  - V = R(s2) + γ × V₁(s2) = 10 + 0.9(10.0) = 10 + 9.0 = **19.0** ✓\n",
    "\n",
    "**V₂(s2) = max(19.0, 11.8, 14.5, 19.0) = 19.0**\n",
    "\n",
    "**Best Actions**: up or right (both keep agent in s2 or hit wall)\n",
    "\n",
    "---\n",
    "\n",
    "### State s3 (Bottom-Left, R=1)\n",
    "\n",
    "Calculate value for each action:\n",
    "\n",
    "- **up**: Moves to s1\n",
    "  - V = R(s3) + γ × V₁(s1) = 1 + 0.9(5.0) = 1 + 4.5 = **5.5** ✓\n",
    "\n",
    "- **down**: Hits wall → stays at s3\n",
    "  - V = R(s3) + γ × V₁(s3) = 1 + 0.9(1.0) = 1 + 0.9 = **1.9**\n",
    "\n",
    "- **left**: Hits wall → stays at s3\n",
    "  - V = R(s3) + γ × V₁(s3) = 1 + 0.9(1.0) = 1 + 0.9 = **1.9**\n",
    "\n",
    "- **right**: Moves to s4\n",
    "  - V = R(s3) + γ × V₁(s4) = 1 + 0.9(2.0) = 1 + 1.8 = **2.8**\n",
    "\n",
    "**V₂(s3) = max(5.5, 1.9, 1.9, 2.8) = 5.5**\n",
    "\n",
    "**Best Action**: up (move to s1)\n",
    "\n",
    "---\n",
    "\n",
    "### State s4 (Bottom-Right, R=2)\n",
    "\n",
    "Calculate value for each action:\n",
    "\n",
    "- **up**: Moves to s2\n",
    "  - V = R(s4) + γ × V₁(s2) = 2 + 0.9(10.0) = 2 + 9.0 = **11.0** ✓\n",
    "\n",
    "- **down**: Hits wall → stays at s4\n",
    "  - V = R(s4) + γ × V₁(s4) = 2 + 0.9(2.0) = 2 + 1.8 = **3.8**\n",
    "\n",
    "- **left**: Moves to s3\n",
    "  - V = R(s4) + γ × V₁(s3) = 2 + 0.9(1.0) = 2 + 0.9 = **2.9**\n",
    "\n",
    "- **right**: Hits wall → stays at s4\n",
    "  - V = R(s4) + γ × V₁(s4) = 2 + 0.9(2.0) = 2 + 1.8 = **3.8**\n",
    "\n",
    "**V₂(s4) = max(11.0, 3.8, 2.9, 3.8) = 11.0**\n",
    "\n",
    "**Best Action**: up (move to s2)\n",
    "\n",
    "---\n",
    "\n",
    "### Updated Value Function After Iteration 2\n",
    "\n",
    "| State | V₂(s) | Best Action |\n",
    "|-------|-------|-------------|\n",
    "| s1    | 14.0  | right       |\n",
    "| s2    | 19.0  | up/right    |\n",
    "| s3    | 5.5   | up          |\n",
    "| s4    | 11.0  | up          |\n",
    "\n",
    "**Grid Visualization:**\n",
    "```\n",
    "[14.0]  [19.0]\n",
    "[5.5]   [11.0]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Summary Table\n",
    "\n",
    "| State | V₀ | V₁  | V₂   | Optimal Action |\n",
    "|-------|-----|-----|------|----------------|\n",
    "| s1    | 0.0 | 5.0 | 14.0 | right          |\n",
    "| s2    | 0.0 | 10.0| 19.0 | up/right       |\n",
    "| s3    | 0.0 | 1.0 | 5.5  | up             |\n",
    "| s4    | 0.0 | 2.0 | 11.0 | up             |\n",
    "\n",
    "---\n",
    "\n",
    "## Key Observations\n",
    "\n",
    "1. **Value Propagation**: Values increase with each iteration as the agent learns to account for future rewards through the discount factor.\n",
    "\n",
    "2. **Optimal Behavior Emerging**: After two iterations, the policy is gravitating toward state s2 (highest immediate reward of 10), with:\n",
    "   - s1 → right (to s2)\n",
    "   - s3 → up (to s1, then eventually to s2)\n",
    "   - s4 → up (directly to s2)\n",
    "   - s2 → stay (up or right keeps agent in high-reward state)\n",
    "\n",
    "3. **Convergence**: The values are still changing, indicating that more iterations would be needed to reach the optimal value function V*.\n",
    "\n",
    "4. **Policy Improvement**: The initial policy (all states go up) was suboptimal. After two iterations of value iteration, we've identified better actions that maximize expected cumulative reward.\n",
    "\n",
    "---\n",
    "\n",
    "## Mathematical Process\n",
    "\n",
    "The value iteration process follows this pattern:\n",
    "\n",
    "**Iteration 1**: Values reflect only immediate rewards\n",
    "\\[ V₁(s) = R(s) + \\gamma × 0 = R(s) \\]\n",
    "\n",
    "**Iteration 2**: Values incorporate one-step lookahead\n",
    "\\[ V₂(s) = \\max_a [R(s) + \\gamma × V₁(s')] \\]\n",
    "\n",
    "**Subsequent Iterations**: Continue until convergence\n",
    "\\[ V_{k+1}(s) = \\max_a [R(s) + \\gamma × V_k(s')] \\]\n",
    "\n",
    "The algorithm converges when the maximum change in value function falls below a threshold:\n",
    "\\[ \\max_s |V_{k+1}(s) - V_k(s)| < \\theta \\]\n",
    "\n",
    "---\n",
    "## Talking Points:\n",
    "\n",
    "I performed two iterations of Value Iteration on a 2×2 gridworld with rewards of 5, 10, 1, and 2 for states s1, s2, s3, and s4 respectively, using a discount factor of 0.9.\n",
    "\n",
    "**Iteration 1** produced values equal to the immediate rewards (5.0, 10.0, 1.0, 2.0) since all successor states started at zero. \n",
    "**Iteration 2** showed significant value propagation: s1 increased to 14.0, s2 to 19.0, s3 to 5.5, and s4 to 11.0.\n",
    "\n",
    "The optimal policy emerged clearly all states gravitate toward s2, which has the highest immediate reward. State s1's best action is to move right to s2, s3 should move up toward s1 (then to s2), and s4 should move up directly to s2. State s2 itself benefits from staying put.\n",
    "\n",
    "This demonstrates how value iteration uses the Bellman optimality equation to propagate future reward information backward through the state space, allowing the agent to discover that maximizing long-term value means navigating to and remaining in high-reward regions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd375556",
   "metadata": {},
   "source": [
    "## Problem 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34ed6217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PROBLEM 3: 5x5 Gridworld with Value Iteration\n",
      "======================================================================\n",
      "GridWorld Environment Initialized\n",
      "Size: 5x5\n",
      "Goal State: (4, 4) (Reward: +10)\n",
      "Grey States: [(1, 2), (3, 0), (0, 4)] (Reward: -5)\n",
      "Regular States: All others (Reward: -1)\n",
      "\n",
      "Reward Matrix:\n",
      "[[-1. -1. -1. -1. -5.]\n",
      " [-1. -1. -5. -1. -1.]\n",
      " [-1. -1. -1. -1. -1.]\n",
      " [-5. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1. 10.]]\n",
      "\n",
      "Hyperparameters:\n",
      "  Discount Factor (γ): 0.9\n",
      "  Convergence Threshold (θ): 0.0001\n",
      "\n",
      "======================================================================\n",
      "STANDARD VALUE ITERATION\n",
      "======================================================================\n",
      "Iteration 1: Max Delta = 5.000000\n",
      "Iteration 9: Max Delta = 0.000000\n",
      "\n",
      "Converged after 9 iterations!\n",
      "Time elapsed: 0.003006 seconds\n",
      "\n",
      "Optimal State-Value Function V*:\n",
      "======================================================================\n",
      "Row 0:   -5.70    -5.22    -4.69    -4.10    -7.44\n",
      "Row 1:   -5.22    -4.69    -8.10    -3.44    -2.71\n",
      "Row 2:   -4.69    -4.10    -3.44    -2.71    -1.90\n",
      "Row 3:   -8.10    -3.44    -2.71    -1.90    -1.00\n",
      "Row 4:   -3.44    -2.71    -1.90    -1.00     0.00\n",
      "======================================================================\n",
      "\n",
      "Optimal Policy π*:\n",
      "======================================================================\n",
      "Row 0:   →    →    →    ↓    ↓\n",
      "Row 1:   →    ↓    →    →    ↓\n",
      "Row 2:   →    →    →    →    ↓\n",
      "Row 3:   →    →    →    →    ↓\n",
      "Row 4:   →    →    →    →    G\n",
      "======================================================================\n",
      "Legend: → (Right), ← (Left), ↓ (Down), ↑ (Up), G (Goal)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "IN-PLACE VALUE ITERATION\n",
      "======================================================================\n",
      "Iteration 1: Max Delta = 5.000000\n",
      "Iteration 9: Max Delta = 0.000000\n",
      "\n",
      "Converged after 9 iterations!\n",
      "Time elapsed: 0.001000 seconds\n",
      "\n",
      "Optimal State-Value Function V*:\n",
      "======================================================================\n",
      "Row 0:   -5.70    -5.22    -4.69    -4.10    -7.44\n",
      "Row 1:   -5.22    -4.69    -8.10    -3.44    -2.71\n",
      "Row 2:   -4.69    -4.10    -3.44    -2.71    -1.90\n",
      "Row 3:   -8.10    -3.44    -2.71    -1.90    -1.00\n",
      "Row 4:   -3.44    -2.71    -1.90    -1.00     0.00\n",
      "======================================================================\n",
      "\n",
      "Optimal Policy π*:\n",
      "======================================================================\n",
      "Row 0:   →    →    →    ↓    ↓\n",
      "Row 1:   →    ↓    →    →    ↓\n",
      "Row 2:   →    →    →    →    ↓\n",
      "Row 3:   →    →    →    →    ↓\n",
      "Row 4:   →    →    →    →    G\n",
      "======================================================================\n",
      "Legend: → (Right), ← (Left), ↓ (Down), ↑ (Up), G (Goal)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "PERFORMANCE COMPARISON\n",
      "======================================================================\n",
      "\n",
      "1. CONVERGENCE METRICS\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Standard VI</th>\n",
       "      <th>In-Place VI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iterations to Converge</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Optimization Time (s)</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Final Max Delta</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avg Time per Iteration (ms)</td>\n",
       "      <td>0.3340</td>\n",
       "      <td>0.1112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Metric Standard VI In-Place VI\n",
       "0       Iterations to Converge           9           9\n",
       "1        Optimization Time (s)    0.003006    0.001000\n",
       "2              Final Max Delta  0.00000000  0.00000000\n",
       "3  Avg Time per Iteration (ms)      0.3340      0.1112"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. SPEEDUP ANALYSIS\n",
      "----------------------------------------------------------------------\n",
      "In-Place Speedup Factor: 3.00x faster\n",
      "Time Saved: 2.005 ms\n",
      "Iteration Difference: 0 iterations\n",
      "\n",
      "3. COMPUTATIONAL COMPLEXITY ANALYSIS\n",
      "----------------------------------------------------------------------\n",
      "Standard Value Iteration:\n",
      "  • Time Complexity: O(k × |S| × |A|) per iteration\n",
      "  • Space Complexity: O(2|S|) - requires two value arrays\n",
      "  • Memory: 2 arrays × 25 states = 50 float values\n",
      "  • Must copy entire array each iteration\n",
      "\n",
      "In-Place Value Iteration:\n",
      "  • Time Complexity: O(k × |S| × |A|) per iteration\n",
      "  • Space Complexity: O(|S|) - requires single value array\n",
      "  • Memory: 1 array × 25 states = 25 float values\n",
      "  • No array copying needed\n",
      "  • Memory savings: 50% reduction\n",
      "\n",
      "Where: |S| = 25 states, |A| = 4 actions, k = iterations\n",
      "\n",
      "4. SOLUTION QUALITY VERIFICATION\n",
      "----------------------------------------------------------------------\n",
      "Value Functions Match: True\n",
      "Policies Match: True\n",
      "Maximum Value Difference: 0.0000000000\n",
      "\n",
      "✓ Both algorithms produce IDENTICAL optimal solutions!\n",
      "\n",
      "5. KEY OBSERVATIONS\n",
      "----------------------------------------------------------------------\n",
      "✓ In-Place VI is more memory efficient (50% reduction)\n",
      "✓ In-Place VI is faster due to:\n",
      "  - No array copying overhead\n",
      "  - Better cache locality (single array)\n",
      "  - Immediate propagation of updated values\n",
      "✓ Both algorithms converge to identical optimal solutions\n",
      "✓ In-Place VI can converge faster in some state orderings\n",
      "✓ For large state spaces, memory savings become critical\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SUMMARY TABLE: STATE VALUES AND OPTIMAL ACTIONS\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Type</th>\n",
       "      <th>Reward</th>\n",
       "      <th>V*(Standard)</th>\n",
       "      <th>V*(In-Place)</th>\n",
       "      <th>Optimal Action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0,0)</td>\n",
       "      <td>Regular</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-5.695</td>\n",
       "      <td>-5.695</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0,1)</td>\n",
       "      <td>Regular</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-5.217</td>\n",
       "      <td>-5.217</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0,2)</td>\n",
       "      <td>Regular</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-4.686</td>\n",
       "      <td>-4.686</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0,3)</td>\n",
       "      <td>Regular</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-4.095</td>\n",
       "      <td>-4.095</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0,4)</td>\n",
       "      <td>Grey</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-7.439</td>\n",
       "      <td>-7.439</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1,0)</td>\n",
       "      <td>Regular</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-5.217</td>\n",
       "      <td>-5.217</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(1,1)</td>\n",
       "      <td>Regular</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-4.686</td>\n",
       "      <td>-4.686</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1,2)</td>\n",
       "      <td>Grey</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-8.095</td>\n",
       "      <td>-8.095</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(1,3)</td>\n",
       "      <td>Regular</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-3.439</td>\n",
       "      <td>-3.439</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(1,4)</td>\n",
       "      <td>Regular</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.710</td>\n",
       "      <td>-2.710</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(2,0)</td>\n",
       "      <td>Regular</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-4.686</td>\n",
       "      <td>-4.686</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(2,1)</td>\n",
       "      <td>Regular</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-4.095</td>\n",
       "      <td>-4.095</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(2,2)</td>\n",
       "      <td>Regular</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-3.439</td>\n",
       "      <td>-3.439</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(2,3)</td>\n",
       "      <td>Regular</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.710</td>\n",
       "      <td>-2.710</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(2,4)</td>\n",
       "      <td>Regular</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.900</td>\n",
       "      <td>-1.900</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(3,0)</td>\n",
       "      <td>Grey</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-8.095</td>\n",
       "      <td>-8.095</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(3,1)</td>\n",
       "      <td>Regular</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-3.439</td>\n",
       "      <td>-3.439</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(3,2)</td>\n",
       "      <td>Regular</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.710</td>\n",
       "      <td>-2.710</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(3,3)</td>\n",
       "      <td>Regular</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.900</td>\n",
       "      <td>-1.900</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(3,4)</td>\n",
       "      <td>Regular</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(4,0)</td>\n",
       "      <td>Regular</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-3.439</td>\n",
       "      <td>-3.439</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(4,1)</td>\n",
       "      <td>Regular</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.710</td>\n",
       "      <td>-2.710</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(4,2)</td>\n",
       "      <td>Regular</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.900</td>\n",
       "      <td>-1.900</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(4,3)</td>\n",
       "      <td>Regular</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(4,4)</td>\n",
       "      <td>Goal</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    State     Type  Reward  V*(Standard)  V*(In-Place) Optimal Action\n",
       "0   (0,0)  Regular    -1.0        -5.695        -5.695          Right\n",
       "1   (0,1)  Regular    -1.0        -5.217        -5.217          Right\n",
       "2   (0,2)  Regular    -1.0        -4.686        -4.686          Right\n",
       "3   (0,3)  Regular    -1.0        -4.095        -4.095           Down\n",
       "4   (0,4)     Grey    -5.0        -7.439        -7.439           Down\n",
       "5   (1,0)  Regular    -1.0        -5.217        -5.217          Right\n",
       "6   (1,1)  Regular    -1.0        -4.686        -4.686           Down\n",
       "7   (1,2)     Grey    -5.0        -8.095        -8.095          Right\n",
       "8   (1,3)  Regular    -1.0        -3.439        -3.439          Right\n",
       "9   (1,4)  Regular    -1.0        -2.710        -2.710           Down\n",
       "10  (2,0)  Regular    -1.0        -4.686        -4.686          Right\n",
       "11  (2,1)  Regular    -1.0        -4.095        -4.095          Right\n",
       "12  (2,2)  Regular    -1.0        -3.439        -3.439          Right\n",
       "13  (2,3)  Regular    -1.0        -2.710        -2.710          Right\n",
       "14  (2,4)  Regular    -1.0        -1.900        -1.900           Down\n",
       "15  (3,0)     Grey    -5.0        -8.095        -8.095          Right\n",
       "16  (3,1)  Regular    -1.0        -3.439        -3.439          Right\n",
       "17  (3,2)  Regular    -1.0        -2.710        -2.710          Right\n",
       "18  (3,3)  Regular    -1.0        -1.900        -1.900          Right\n",
       "19  (3,4)  Regular    -1.0        -1.000        -1.000           Down\n",
       "20  (4,0)  Regular    -1.0        -3.439        -3.439          Right\n",
       "21  (4,1)  Regular    -1.0        -2.710        -2.710          Right\n",
       "22  (4,2)  Regular    -1.0        -1.900        -1.900          Right\n",
       "23  (4,3)  Regular    -1.0        -1.000        -1.000          Right\n",
       "24  (4,4)     Goal    10.0         0.000         0.000            N/A"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================================\n",
    "# GRIDWORLD ENVIRONMENT CLASS (Updated for Problem 3)\n",
    "# ============================================================================\n",
    "\n",
    "class GridWorld():\n",
    "    \"\"\"\n",
    "    GridWorld environment for reinforcement learning.\n",
    "    5x5 grid with goal state, grey penalty states, and regular states.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env_size):\n",
    "        self.env_size = env_size\n",
    "        # Terminal/Goal state at bottom-right corner\n",
    "        self.terminal_state = (4, 4)\n",
    "\n",
    "        # Define the transition probabilities and rewards\n",
    "        self.actions = [(0, 1), (0, -1), (1, 0), (-1, 0)]  # Right, Left, Down, Up\n",
    "        self.action_description = [\"Right\", \"Left\", \"Down\", \"Up\"]\n",
    "        self.action_symbols = [\"→\", \"←\", \"↓\", \"↑\"]\n",
    "\n",
    "        # TASK 1: Update reward function as specified in Problem 3\n",
    "        # Initialize all states with -1 (regular states)\n",
    "        self.reward = np.ones((self.env_size, self.env_size)) * -1\n",
    "\n",
    "        # Grey states (unfavorable): -5\n",
    "        self.grey_states = [(1, 2), (3, 0), (0, 4)]\n",
    "        for state in self.grey_states:\n",
    "            self.reward[state] = -5\n",
    "\n",
    "        # Terminal/Goal state: +10\n",
    "        self.reward[self.terminal_state] = 10\n",
    "\n",
    "        print(\"GridWorld Environment Initialized\")\n",
    "        print(f\"Size: {env_size}x{env_size}\")\n",
    "        print(f\"Goal State: {self.terminal_state} (Reward: +10)\")\n",
    "        print(f\"Grey States: {self.grey_states} (Reward: -5)\")\n",
    "        print(f\"Regular States: All others (Reward: -1)\")\n",
    "        print(\"\\nReward Matrix:\")\n",
    "        print(self.reward)\n",
    "\n",
    "    def step(self, action_index, i, j):\n",
    "        \"\"\"\n",
    "        Returns the next state given the chosen action and current state.\n",
    "\n",
    "        Args:\n",
    "            action_index: Index of the action to take (0=Right, 1=Left, 2=Down, 3=Up)\n",
    "            i, j: Current state coordinates\n",
    "\n",
    "        Returns:\n",
    "            next_i, next_j: Next state coordinates\n",
    "            reward: Reward for the current state\n",
    "            done: Boolean indicating if terminal state reached\n",
    "        \"\"\"\n",
    "        # Transition Probability Matrix: P(s'|s,a) = 1.0 for single state, 0 otherwise\n",
    "        action = self.actions[action_index]\n",
    "        next_i, next_j = i + action[0], j + action[1]\n",
    "\n",
    "        # If action leads outside grid, stay in current state\n",
    "        if not self.is_valid_state(next_i, next_j):\n",
    "            next_i, next_j = i, j\n",
    "\n",
    "        done = self.is_terminal_state(next_i, next_j)\n",
    "        reward = self.reward[i, j]  # Reward based on current state\n",
    "\n",
    "        return next_i, next_j, reward, done\n",
    "\n",
    "    def is_valid_state(self, i, j):\n",
    "        \"\"\"Checks if a state is within the acceptable bounds of the environment.\"\"\"\n",
    "        valid = 0 <= i < self.env_size and 0 <= j < self.env_size\n",
    "        return valid\n",
    "\n",
    "    def is_terminal_state(self, i, j):\n",
    "        \"\"\"Returns True if the state is a terminal state.\"\"\"\n",
    "        return (i, j) == self.terminal_state\n",
    "\n",
    "    def get_size(self):\n",
    "        \"\"\"Returns the size of the environment.\"\"\"\n",
    "        return self.env_size\n",
    "\n",
    "    def get_actions(self):\n",
    "        \"\"\"Returns the list of available actions.\"\"\"\n",
    "        return self.actions\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TASK 1: STANDARD VALUE ITERATION\n",
    "# ============================================================================\n",
    "\n",
    "def value_iteration_standard(env, gamma=0.9, theta=0.0001, max_iterations=1000):\n",
    "    \"\"\"\n",
    "    Standard Value Iteration algorithm using two arrays (synchronous updates).\n",
    "\n",
    "    Algorithm:\n",
    "    1. Initialize V(s) = 0 for all states\n",
    "    2. Repeat until convergence:\n",
    "       - For each state s:\n",
    "         - Calculate Q(s,a) for all actions a\n",
    "         - V_new(s) = max_a Q(s,a)\n",
    "       - Check convergence: if max|V_new - V_old| < theta, stop\n",
    "    3. Extract optimal policy: π(s) = argmax_a Q(s,a)\n",
    "\n",
    "    Args:\n",
    "        env: GridWorld environment\n",
    "        gamma: Discount factor (default 0.9)\n",
    "        theta: Convergence threshold (default 0.0001)\n",
    "        max_iterations: Maximum number of iterations\n",
    "\n",
    "    Returns:\n",
    "        V: Optimal value function\n",
    "        policy: Optimal policy (action indices)\n",
    "        iterations: Number of iterations to converge\n",
    "        elapsed_time: Time taken to converge\n",
    "        convergence_history: List of delta values per iteration\n",
    "    \"\"\"\n",
    "    # Initialize value function to zeros\n",
    "    V = np.zeros((env.env_size, env.env_size))\n",
    "    policy = np.zeros((env.env_size, env.env_size), dtype=int)\n",
    "\n",
    "    iterations = 0\n",
    "    convergence_history = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STANDARD VALUE ITERATION\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        # Create a copy of the current value function (synchronous update)\n",
    "        V_old = V.copy()\n",
    "        delta = 0  # Track maximum change in value function\n",
    "\n",
    "        # Update each state\n",
    "        for i in range(env.env_size):\n",
    "            for j in range(env.env_size):\n",
    "                # Skip terminal state (value is fixed)\n",
    "                if env.is_terminal_state(i, j):\n",
    "                    V[i, j] = 0  # Terminal state value is 0\n",
    "                    continue\n",
    "\n",
    "                # Calculate action values Q(s,a) for all actions\n",
    "                action_values = []\n",
    "                for action_idx in range(len(env.actions)):\n",
    "                    # Get next state and reward\n",
    "                    next_i, next_j, reward, done = env.step(action_idx, i, j)\n",
    "\n",
    "                    # Bellman equation: Q(s,a) = R(s) + γ * V(s')\n",
    "                    q_value = reward + gamma * V_old[next_i, next_j]\n",
    "                    action_values.append(q_value)\n",
    "\n",
    "                # Update value with maximum action value\n",
    "                V[i, j] = max(action_values)\n",
    "\n",
    "                # Update policy with best action\n",
    "                policy[i, j] = np.argmax(action_values)\n",
    "\n",
    "                # Track convergence\n",
    "                delta = max(delta, abs(V[i, j] - V_old[i, j]))\n",
    "\n",
    "        iterations += 1\n",
    "        convergence_history.append(delta)\n",
    "\n",
    "        # Print progress every 10 iterations\n",
    "        if iteration % 10 == 0 or delta < theta:\n",
    "            print(f\"Iteration {iteration + 1}: Max Delta = {delta:.6f}\")\n",
    "\n",
    "        # Check convergence\n",
    "        if delta < theta:\n",
    "            print(f\"\\nConverged after {iterations} iterations!\")\n",
    "            break\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Time elapsed: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "    return V, policy, iterations, elapsed_time, convergence_history\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TASK 2: IN-PLACE VALUE ITERATION\n",
    "# ============================================================================\n",
    "\n",
    "def value_iteration_inplace(env, gamma=0.9, theta=0.0001, max_iterations=1000):\n",
    "    \"\"\"\n",
    "    In-Place Value Iteration algorithm using single array (asynchronous updates).\n",
    "\n",
    "    Difference from standard VI:\n",
    "    - Uses a single value array instead of two\n",
    "    - Updates are immediately reflected in subsequent calculations within the same iteration\n",
    "    - More memory efficient: O(|S|) vs O(2|S|)\n",
    "    - Can converge faster due to immediate propagation of updates\n",
    "\n",
    "    Args:\n",
    "        env: GridWorld environment\n",
    "        gamma: Discount factor (default 0.9)\n",
    "        theta: Convergence threshold (default 0.0001)\n",
    "        max_iterations: Maximum number of iterations\n",
    "\n",
    "    Returns:\n",
    "        V: Optimal value function\n",
    "        policy: Optimal policy (action indices)\n",
    "        iterations: Number of iterations to converge\n",
    "        elapsed_time: Time taken to converge\n",
    "        convergence_history: List of delta values per iteration\n",
    "    \"\"\"\n",
    "    # Initialize value function to zeros\n",
    "    V = np.zeros((env.env_size, env.env_size))\n",
    "    policy = np.zeros((env.env_size, env.env_size), dtype=int)\n",
    "\n",
    "    iterations = 0\n",
    "    convergence_history = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"IN-PLACE VALUE ITERATION\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        delta = 0  # Track maximum change in value function\n",
    "\n",
    "        # Update each state (updates are immediately used)\n",
    "        for i in range(env.env_size):\n",
    "            for j in range(env.env_size):\n",
    "                # Skip terminal state (value is fixed)\n",
    "                if env.is_terminal_state(i, j):\n",
    "                    V[i, j] = 0  # Terminal state value is 0\n",
    "                    continue\n",
    "\n",
    "                # Store old value for convergence check\n",
    "                v_old = V[i, j]\n",
    "\n",
    "                # Calculate action values Q(s,a) for all actions\n",
    "                action_values = []\n",
    "                for action_idx in range(len(env.actions)):\n",
    "                    # Get next state and reward\n",
    "                    next_i, next_j, reward, done = env.step(action_idx, i, j)\n",
    "\n",
    "                    # Bellman equation: Q(s,a) = R(s) + γ * V(s')\n",
    "                    # NOTE: V is updated in-place, so we use current values\n",
    "                    q_value = reward + gamma * V[next_i, next_j]\n",
    "                    action_values.append(q_value)\n",
    "\n",
    "                # Update value with maximum action value (immediately)\n",
    "                V[i, j] = max(action_values)\n",
    "\n",
    "                # Update policy with best action\n",
    "                policy[i, j] = np.argmax(action_values)\n",
    "\n",
    "                # Track convergence\n",
    "                delta = max(delta, abs(V[i, j] - v_old))\n",
    "\n",
    "        iterations += 1\n",
    "        convergence_history.append(delta)\n",
    "\n",
    "        # Print progress every 10 iterations\n",
    "        if iteration % 10 == 0 or delta < theta:\n",
    "            print(f\"Iteration {iteration + 1}: Max Delta = {delta:.6f}\")\n",
    "\n",
    "        # Check convergence\n",
    "        if delta < theta:\n",
    "            print(f\"\\nConverged after {iterations} iterations!\")\n",
    "            break\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Time elapsed: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "    return V, policy, iterations, elapsed_time, convergence_history\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def print_value_function(V, env):\n",
    "    \"\"\"Display the value function in a formatted grid.\"\"\"\n",
    "    print(\"\\nOptimal State-Value Function V*:\")\n",
    "    print(\"=\"*70)\n",
    "    for i in range(env.env_size):\n",
    "        row_str = \"  \".join([f\"{V[i, j]:7.2f}\" for j in range(env.env_size)])\n",
    "        print(f\"Row {i}: {row_str}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "\n",
    "def print_policy(policy, env):\n",
    "    \"\"\"Display the optimal policy in a formatted grid with action symbols.\"\"\"\n",
    "    print(\"\\nOptimal Policy π*:\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    policy_grid = []\n",
    "    for i in range(env.env_size):\n",
    "        row = []\n",
    "        for j in range(env.env_size):\n",
    "            if env.is_terminal_state(i, j):\n",
    "                row.append(\"G\")  # Goal\n",
    "            else:\n",
    "                row.append(env.action_symbols[policy[i, j]])\n",
    "        policy_grid.append(row)\n",
    "\n",
    "    for i, row in enumerate(policy_grid):\n",
    "        row_str = \"  \".join([f\"{cell:>3}\" for cell in row])\n",
    "        print(f\"Row {i}: {row_str}\")\n",
    "\n",
    "    print(\"=\"*70)\n",
    "    print(\"Legend: → (Right), ← (Left), ↓ (Down), ↑ (Up), G (Goal)\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "\n",
    "def plot_convergence(history_standard, history_inplace):\n",
    "    \"\"\"Plot convergence comparison between standard and in-place VI.\"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot 1: Delta over iterations\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, len(history_standard) + 1), history_standard, \n",
    "             'b-o', label='Standard VI', linewidth=2, markersize=6)\n",
    "    plt.plot(range(1, len(history_inplace) + 1), history_inplace, \n",
    "             'r-s', label='In-Place VI', linewidth=2, markersize=6)\n",
    "    plt.xlabel('Iteration', fontsize=12)\n",
    "    plt.ylabel('Max Delta (|V_new - V_old|)', fontsize=12)\n",
    "    plt.title('Convergence Rate Comparison', fontsize=14, fontweight='bold')\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.yscale('log')\n",
    "\n",
    "    # Plot 2: Bar chart of iterations\n",
    "    plt.subplot(1, 2, 2)\n",
    "    algorithms = ['Standard VI', 'In-Place VI']\n",
    "    iterations = [len(history_standard), len(history_inplace)]\n",
    "    colors = ['blue', 'red']\n",
    "    bars = plt.bar(algorithms, iterations, color=colors, alpha=0.7, edgecolor='black')\n",
    "    plt.ylabel('Number of Iterations', fontsize=12)\n",
    "    plt.title('Iterations to Convergence', fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}',\n",
    "                ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PERFORMANCE COMPARISON\n",
    "# ============================================================================\n",
    "\n",
    "def compare_performance(results_standard, results_inplace):\n",
    "    \"\"\"\n",
    "    Compare performance metrics between standard and in-place value iteration.\n",
    "\n",
    "    Args:\n",
    "        results_standard: Tuple (V, policy, iterations, time, history)\n",
    "        results_inplace: Tuple (V, policy, iterations, time, history)\n",
    "    \"\"\"\n",
    "    V_std, policy_std, iters_std, time_std, hist_std = results_standard\n",
    "    V_inp, policy_inp, iters_inp, time_inp, hist_inp = results_inplace\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PERFORMANCE COMPARISON\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # 1. Convergence Metrics\n",
    "    print(\"\\n1. CONVERGENCE METRICS\")\n",
    "    print(\"-\"*70)\n",
    "\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Metric': [\n",
    "            'Iterations to Converge',\n",
    "            'Optimization Time (s)',\n",
    "            'Final Max Delta',\n",
    "            'Avg Time per Iteration (ms)'\n",
    "        ],\n",
    "        'Standard VI': [\n",
    "            iters_std,\n",
    "            f'{time_std:.6f}',\n",
    "            f'{hist_std[-1]:.8f}',\n",
    "            f'{(time_std/iters_std)*1000:.4f}'\n",
    "        ],\n",
    "        'In-Place VI': [\n",
    "            iters_inp,\n",
    "            f'{time_inp:.6f}',\n",
    "            f'{hist_inp[-1]:.8f}',\n",
    "            f'{(time_inp/iters_inp)*1000:.4f}'\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    display(comparison_df)\n",
    "\n",
    "    # 2. Speedup Analysis\n",
    "    print(\"\\n2. SPEEDUP ANALYSIS\")\n",
    "    print(\"-\"*70)\n",
    "    speedup = time_std / time_inp\n",
    "    time_saved = (time_std - time_inp) * 1000  # Convert to ms\n",
    "    iter_diff = iters_std - iters_inp\n",
    "\n",
    "    print(f\"In-Place Speedup Factor: {speedup:.2f}x faster\")\n",
    "    print(f\"Time Saved: {time_saved:.3f} ms\")\n",
    "    print(f\"Iteration Difference: {iter_diff} iterations\")\n",
    "\n",
    "    # 3. Computational Complexity\n",
    "    print(\"\\n3. COMPUTATIONAL COMPLEXITY ANALYSIS\")\n",
    "    print(\"-\"*70)\n",
    "    print(\"Standard Value Iteration:\")\n",
    "    print(\"  • Time Complexity: O(k × |S| × |A|) per iteration\")\n",
    "    print(\"  • Space Complexity: O(2|S|) - requires two value arrays\")\n",
    "    print(f\"  • Memory: 2 arrays × 25 states = 50 float values\")\n",
    "    print(\"  • Must copy entire array each iteration\")\n",
    "\n",
    "    print(\"\\nIn-Place Value Iteration:\")\n",
    "    print(\"  • Time Complexity: O(k × |S| × |A|) per iteration\")\n",
    "    print(\"  • Space Complexity: O(|S|) - requires single value array\")\n",
    "    print(f\"  • Memory: 1 array × 25 states = 25 float values\")\n",
    "    print(\"  • No array copying needed\")\n",
    "    print(\"  • Memory savings: 50% reduction\")\n",
    "\n",
    "    print(f\"\\nWhere: |S| = 25 states, |A| = 4 actions, k = iterations\")\n",
    "\n",
    "    # 4. Solution Quality Verification\n",
    "    print(\"\\n4. SOLUTION QUALITY VERIFICATION\")\n",
    "    print(\"-\"*70)\n",
    "\n",
    "    values_match = np.allclose(V_std, V_inp, rtol=1e-5, atol=1e-8)\n",
    "    policy_match = np.array_equal(policy_std, policy_inp)\n",
    "    max_value_diff = np.max(np.abs(V_std - V_inp))\n",
    "\n",
    "    print(f\"Value Functions Match: {values_match}\")\n",
    "    print(f\"Policies Match: {policy_match}\")\n",
    "    print(f\"Maximum Value Difference: {max_value_diff:.10f}\")\n",
    "\n",
    "    if values_match and policy_match:\n",
    "        print(\"\\n✓ Both algorithms produce IDENTICAL optimal solutions!\")\n",
    "\n",
    "    # 5. Key Observations\n",
    "    print(\"\\n5. KEY OBSERVATIONS\")\n",
    "    print(\"-\"*70)\n",
    "    print(\"✓ In-Place VI is more memory efficient (50% reduction)\")\n",
    "    print(\"✓ In-Place VI is faster due to:\")\n",
    "    print(\"  - No array copying overhead\")\n",
    "    print(\"  - Better cache locality (single array)\")\n",
    "    print(\"  - Immediate propagation of updated values\")\n",
    "    print(\"✓ Both algorithms converge to identical optimal solutions\")\n",
    "    print(\"✓ In-Place VI can converge faster in some state orderings\")\n",
    "    print(\"✓ For large state spaces, memory savings become critical\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*70)\n",
    "    print(\"PROBLEM 3: 5x5 Gridworld with Value Iteration\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Create environment\n",
    "    env = GridWorld(env_size=5)\n",
    "\n",
    "    # Set hyperparameters\n",
    "    GAMMA = 0.9  # Discount factor\n",
    "    THETA = 0.0001  # Convergence threshold\n",
    "\n",
    "    print(f\"\\nHyperparameters:\")\n",
    "    print(f\"  Discount Factor (γ): {GAMMA}\")\n",
    "    print(f\"  Convergence Threshold (θ): {THETA}\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # TASK 1: Run Standard Value Iteration\n",
    "    # ========================================================================\n",
    "    results_standard = value_iteration_standard(env, gamma=GAMMA, theta=THETA)\n",
    "    V_standard, policy_standard, iters_std, time_std, history_std = results_standard\n",
    "\n",
    "    # Display results\n",
    "    print_value_function(V_standard, env)\n",
    "    print_policy(policy_standard, env)\n",
    "\n",
    "    # ========================================================================\n",
    "    # TASK 2: Run In-Place Value Iteration\n",
    "    # ========================================================================\n",
    "    results_inplace = value_iteration_inplace(env, gamma=GAMMA, theta=THETA)\n",
    "    V_inplace, policy_inplace, iters_inp, time_inp, history_inp = results_inplace\n",
    "\n",
    "    # Display results\n",
    "    print_value_function(V_inplace, env)\n",
    "    print_policy(policy_inplace, env)\n",
    "\n",
    "    # ========================================================================\n",
    "    # COMPARE PERFORMANCE\n",
    "    # ========================================================================\n",
    "    compare_performance(results_standard, results_inplace)\n",
    "\n",
    "    # ========================================================================\n",
    "    # PLOT CONVERGENCE\n",
    "    # ========================================================================\n",
    "    plot_convergence(history_std, history_inp)\n",
    "\n",
    "    # ========================================================================\n",
    "    # CREATE SUMMARY TABLE\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SUMMARY TABLE: STATE VALUES AND OPTIMAL ACTIONS\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    summary_data = []\n",
    "    for i in range(env.env_size):\n",
    "        for j in range(env.env_size):\n",
    "            state_type = \"Goal\" if (i,j) == env.terminal_state else                         \"Grey\" if (i,j) in env.grey_states else \"Regular\"\n",
    "            action = \"N/A\" if (i,j) == env.terminal_state else                     env.action_description[policy_standard[i, j]]\n",
    "\n",
    "            summary_data.append({\n",
    "                'State': f'({i},{j})',\n",
    "                'Type': state_type,\n",
    "                'Reward': env.reward[i, j],\n",
    "                'V*(Standard)': round(V_standard[i, j], 3),\n",
    "                'V*(In-Place)': round(V_inplace[i, j], 3),\n",
    "                'Optimal Action': action\n",
    "            })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    display(summary_df)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611777ad",
   "metadata": {},
   "source": [
    "## Talking Point:\n",
    "I implemented and compared two variants of Value Iteration on a 5×5 gridworld with a goal state at (4,4) with +10 reward, three grey penalty states at positions (1,2), (3,0), and (0,4) with -5 rewards, and regular states with -1 rewards, using a discount factor γ = 0.9.\n",
    "\n",
    "**Standard Value Iteration** converged in 9 iterations taking 0.003 seconds using synchronous updates with two value arrays.\n",
    "**In-Place Value Iteration** also converged in 9 iterations but completed in 0.001 seconds—achieving a 3x speedup—by using a single array with asynchronous updates where values are immediately propagated.\n",
    "\n",
    "Both algorithms produced identical optimal solutions with the same value function and policy. The optimal policy shows the agent navigating efficiently toward the goal, with most states choosing \"right\" (→) or \"down\" (↓) actions to create diagonal paths. Grey penalty states show significantly lower values (-7.44 to -8.10) compared to their neighbors, demonstrating the agent's learned avoidance behavior. For example, state (1,2) with the grey penalty has V* = -8.10, while adjacent regular states range from -4.69 to -3.44.\n",
    "\n",
    "The key advantage of in-place VI is 50% memory reduction (requiring only one array versus two), which becomes critical for large state spaces. The 3x speedup comes from eliminating array copying overhead and achieving better cache locality. Both methods converge in the same number of iterations here, but in-place VI's immediate value propagation can sometimes accelerate convergence depending on state update ordering.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
